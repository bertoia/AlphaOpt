{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this if you can't import AlphaOpt\n",
    "# Alternatively, use os.chdir('[AlphaOpt_directory]')\n",
    "import os\n",
    "#..\\AlphaOpt\\experiments\\template\n",
    "#..\\AlphaOpt\\experiments\n",
    "%cd \"..\"\n",
    "#..\\AlphaOpt\n",
    "%cd \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import GPyOpt\n",
    "import GPy\n",
    "\n",
    "from AlphaOpt import components\n",
    "from AlphaOpt.CustomCostModel import CustomCostModel as CostModel\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get classes which have at least 70 examples\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples, h, w = lfw_people.images.shape\n",
    "X = lfw_people.data\n",
    "y = lfw_people.target\n",
    "num_classes = lfw_people.target_names.shape[0]\n",
    "\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(X, y, test_size=0.3, random_state=4246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shapeData(data, h=h, w=w):\n",
    "    return data.reshape(data.shape[0], 1, h, w).astype('float32')\n",
    "\n",
    "def normalize(data):\n",
    "    return data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = normalize(shapeData(X_train))\n",
    "X_test = normalize(shapeData(X_test))\n",
    "y_train = np_utils.to_categorical(y_train_raw)\n",
    "y_test = np_utils.to_categorical(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model(dropout_rate=0.25, \n",
    "                   num_features=32, \n",
    "                   feature_size=5, \n",
    "                   pool_size=(2,2), \n",
    "                   fully_connected_size=256):\n",
    "    \"\"\"Baseline model with 1 convolution, 1 max pooling and 2 fully connected layers\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(num_features, feature_size, feature_size, \n",
    "                            border_mode='valid', input_shape=(1, h, w), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(fully_connected_size, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manual_model = baseline_model()\n",
    "manual_model.fit(X_train, y_train, \n",
    "              validation_data=(X_test, y_test), \n",
    "              nb_epoch=40, \n",
    "              batch_size=50,\n",
    "              verbose=1)\n",
    "manual_model.evaluate(X_test, y_test)[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GP for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_accuracy(x):\n",
    "    print(x)\n",
    "    model = baseline_model(dropout_rate=x[0,0],\n",
    "                           num_features=int(x[0,2]),\n",
    "                           feature_size=int(x[0,3]),\n",
    "                           pool_size=(int(x[0,4]),int(x[0,4])))\n",
    "#                            fully_connected_size=x[0,4])\n",
    "    model.fit(X_train, y_train, \n",
    "              validation_data=(X_test, y_test), \n",
    "              nb_epoch=int(x[0,1]), \n",
    "              batch_size=50,\n",
    "              verbose=1)\n",
    "    model.summary()\n",
    "    return 1 / model.evaluate(X_test, y_test)[1]  # returns 1/accuracy\n",
    "    \n",
    "domain = [{'name': 'dropout_rate', 'type': 'continuous', 'domain': (0.01,0.99)},\n",
    "          {'name': 'num_epoch', 'type': 'discrete', 'domain': range(10,41,10)},\n",
    "          {'name': 'num_features', 'type': 'discrete', 'domain': range(10,101,10)},\n",
    "          {'name': 'feature_size', 'type': 'discrete', 'domain': range(2,6)},\n",
    "          {'name': 'pool_size', 'type': 'discrete', 'domain': range(1,6)}]\n",
    "#           {'name': 'fully_connected_size', 'type': 'discrete', 'domain': range(num_classes,301,50)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "objective = GPyOpt.core.task.SingleObjective(cnn_accuracy)\n",
    "space = GPyOpt.Design_space(space=domain)\n",
    "X_init = GPyOpt.util.stats.initial_design('random', space, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bayesian Optimization Components\n",
    "# GP models\n",
    "model = GPyOpt.models.GPModel(kernel=GPy.kern.Matern52(input_dim=2, ARD=True),optimize_restarts=5,verbose=False)\n",
    "cost = CostModel(GPy.kern.Matern52(input_dim=2, ARD=True), 'evaluation_time')\n",
    "\n",
    "# Decision models\n",
    "aquisition_optimizer = GPyOpt.optimization.AcquisitionOptimizer(space)\n",
    "aquisition = GPyOpt.acquisitions.EI.AcquisitionEI(model, space, aquisition_optimizer)\n",
    "evaluator = GPyOpt.core.evaluators.Sequential(aquisition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.13880445   30.          100.            2.            5.        ]]\n",
      "Train on 901 samples, validate on 387 samples\n",
      "Epoch 1/30\n",
      "901/901 [==============================] - 14s - loss: 1.7212 - acc: 0.3907 - val_loss: 1.6582 - val_acc: 0.4238\n",
      "Epoch 2/30\n",
      "901/901 [==============================] - 19s - loss: 1.6937 - acc: 0.4062 - val_loss: 1.6423 - val_acc: 0.4238\n",
      "Epoch 3/30\n",
      "650/901 [====================>.........] - ETA: 6s - loss: 1.6497 - acc: 0.4015"
     ]
    }
   ],
   "source": [
    "# Combine everything\n",
    "bo = GPyOpt.methods.ModularBayesianOptimization(model=model,\n",
    "                                                space=space,\n",
    "                                                objective=objective,\n",
    "                                                acquisition=aquisition,\n",
    "                                                evaluator=evaluator,\n",
    "                                                X_init=X_init,\n",
    "                                                cost=cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iter= 20\n",
    "bo.run_optimization(max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bo.plot_acquisition()\n",
    "bo.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bo.X[np.argmin(opt.Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
